{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Copy of Stacked and Concatenated XGBoost.ipynb","provenance":[{"file_id":"1LuV95O4a6PPjZbB5y_Qel-M4WipM7vUf","timestamp":1585036692075},{"file_id":"https://github.com/GeorgeII/ML-university-course/blob/master/2lab/XGBoost.ipynb","timestamp":1584312691231},{"file_id":"https://github.com/GeorgeII/ML-university-course/blob/master/2lab/XGBoost.ipynb","timestamp":1584298094714}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"id":"bMIkvIAOCDUe","colab_type":"code","colab":{}},"source":["# Before executing this bash cell you need to upload all the zip files \n","# gracefully prepared by me into the /content directory.\n","# Then execute this cell.\n","# It'll create a data/train relative directory and unzip the uploaded files.\n","\n","%%shell\n","rm -r /content/data/\n","mkdir -p /content/data/train\n","\n","for i in {0..11}\n","do\n","  unzip \"/content/train$i.zip\" -d /content/data/train\n","  unzip \"/content/train0$i.zip\" -d /content/data/train\n","done"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2yPENn3D6xxt","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from glob import glob\n","import os\n","from PIL import Image\n","import numpy as np\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3j9GgFQ6xx5","colab_type":"code","outputId":"b5a849b7-b0cb-4cb8-d8ed-f38e413069c3","executionInfo":{"status":"ok","timestamp":1585034781839,"user_tz":-240,"elapsed":5884,"user":{"displayName":"George Zorikov","photoUrl":"","userId":"03587534006447719624"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["#%tensorflow_version 2.x\n","\n","from keras.applications.resnet50 import ResNet50\n","from keras.preprocessing import image\n","from keras.applications.resnet50 import preprocess_input, decode_predictions\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","random.seed(34)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"uxYoDCzV6xyB","colab_type":"code","colab":{}},"source":["# Скачайте полные данные отсюда https://www.kaggle.com/c/dogs-vs-cats/data (примерно 820мб)\n","# У вас должно быть две папки train и test. Однако в данном задании мы не будем использвать test выборку\n","# Функцию для чтения данных мы реализовали за вас\n","\n","def read_dataset(path):\n","    X = []\n","    y = []\n","    \n","    image_paths_list = glob(os.path.join(path, 'train', '*.jpg'))\n","    image_paths_sample = random.sample(image_paths_list, 10000)\n","\n","    for image_path in image_paths_sample:\n","        image_name = os.path.basename(image_path)\n","        image_name_parts = image_name.split('.')\n","        label = image_name_parts[0] if len(image_name_parts) == 3 else None\n","\n","        if label:\n","            y.append(int(label == 'cat'))\n","            \n","        \n","        x = image.img_to_array(image.load_img(image_path, target_size=(224, 224)))\n","        x = preprocess_input(x)\n","            \n","        X.append(x)\n","            \n","    return np.array(X), np.array(y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WqZGRnAS6xyI","colab_type":"text"},"source":["Перепишите код read_dataset() таким образом чтобы читать изображения пачками по 1000 и сразу применять предобученный ResNet на них, сохраняя только полученные вектора как множество X. Примените эту функцию на всём датасете 25000 изображений."]},{"cell_type":"code","metadata":{"id":"c_-Sa1Nf6xyK","colab_type":"code","colab":{}},"source":["from tqdm import tqdm_notebook\n","\n","train_directory = \"data/\"\n","batch_size = 1000\n","images_number = 10000\n","\n","def read_dataset(path):\n","    \"\"\" X should be numpy array from the start. Otherwise it takes too much memory.\n","    \"\"\"\n","\n","    X = np.array([])\n","    y = np.array([])\n","    \n","    image_paths_list = glob(os.path.join(path, 'train', '*.jpg'))\n","    image_paths_list = random.sample(image_paths_list, images_number)\n","    \n","    np.random.shuffle(image_paths_list)\n","    \n","    # split into array of batch_size length arrays\n","    splitted_image_paths_list = np.split(np.array(image_paths_list), int(len(image_paths_list) / batch_size))\n","    \n","    for image_path_batch in tqdm_notebook(splitted_image_paths_list, desc='Batches'):\n","        x_batch = []\n","        y_batch = []\n","        \n","        for image_path in tqdm_notebook(image_path_batch, desc='Current batch', leave=False):\n","            image_name = os.path.basename(image_path)\n","            image_name_parts = image_name.split('.')\n","            label = image_name_parts[0] if len(image_name_parts) == 3 else None\n","            \n","            if label:\n","                y_batch.append(int(label == 'cat'))\n","            \n","            x = image.img_to_array(image.load_img(image_path, target_size=(224, 224)))#, dtype=np.uint8)\n","\n","            '''if x_batch.size == 0:\n","              x_batch = x[None,:,:,:]\n","            else:\n","              x_batch = np.concatenate([x_batch, x[None,:,:,:]], axis=0)'''\n","            x_batch.append(x)\n","        \n","\n","        x_batch = preprocess_input(np.array(x_batch))\n","        y_batch = np.array(y_batch)\n","        \n","        if X.size == 0:\n","          X = x_batch\n","          y = y_batch\n","        else:\n","          X = np.concatenate([X, x_batch], axis=0)\n","          y = np.concatenate([y, y_batch], axis=0)\n","    \n","    return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ZdQsOFR6xyS","colab_type":"code","colab":{}},"source":["# Используйте функцию read_dataset чтобы получить обучающую выборку\n","features, labels = read_dataset(\"/content/data\")\n","\n","# Проверьте размерности загруженных данных\n","print(features.shape)\n","print(labels.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Z5mukm86xyY","colab_type":"code","outputId":"7812faeb-83e8-4bf9-f7b1-7d566382e83d","executionInfo":{"status":"ok","timestamp":1585034885556,"user_tz":-240,"elapsed":1871,"user":{"displayName":"George Zorikov","photoUrl":"","userId":"03587534006447719624"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# с помощью функции train_test_split поделите выборку на train и test в отношении 70/30\n","# В качестве признаков используйте эмбеддинги, полученные на предыдущем шаге\n","features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.3)\n","print(features_train.shape)\n","print(labels_train.shape)\n","print(features_test.shape)\n","print(labels_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(7000, 224, 224, 3)\n","(7000,)\n","(3000, 224, 224, 3)\n","(3000,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZgY62IHvg0JF","colab_type":"text"},"source":["**Что такое эмбеддинг в данном контексте? Как я понял, надо преобразовать картинку размерности (224, 244, 3) в одномерный массив длины m?  Не ясно при чем здесь ResNet**"]},{"cell_type":"code","metadata":{"id":"P5_0ihzY6xyg","colab_type":"code","colab":{}},"source":["# Создаём модель для получения эмбеддингов\n","model = ResNet50(weights='imagenet')\n","\n","# Используя объект model постройте эмбеддинги для обучающей выборки\n","embeddings = model.predict(features_train)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDpYE_rQiWYx","colab_type":"text"},"source":["Попытка классифицировать свою кошку с помощью ResNet."]},{"cell_type":"code","metadata":{"id":"eBp1iVcWss8J","colab_type":"code","colab":{}},"source":["!unzip /content/jerry.zip -d /content/data/my-pet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bypvn3RCoqaG","colab_type":"code","outputId":"af0b199e-e344-4ee9-e68d-80b947a83224","executionInfo":{"status":"ok","timestamp":1585035524668,"user_tz":-240,"elapsed":6321,"user":{"displayName":"George Zorikov","photoUrl":"","userId":"03587534006447719624"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["# check my own pet photos\n","def read_my_pet_dataset(path):\n","    X = []\n","    \n","    image_paths_list = glob(os.path.join(path, 'my-pet', '*.jpg'))\n","\n","    for image_path in image_paths_list:\n","        image_name = os.path.basename(image_path)        \n","        x = image.img_to_array(image.load_img(image_path, target_size=(224, 224)))\n","        x = preprocess_input(x)\n","            \n","        X.append(x)\n","            \n","    return np.array(X)\n","\n","\n","pet_features = read_my_pet_dataset(\"data/\")\n","print(pet_features.shape)\n","\n","pet_predictions = model.predict(pet_features)\n","print(decode_predictions(pet_predictions, top=1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(16, 224, 224, 3)\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","40960/35363 [==================================] - 0s 0us/step\n","[[('n02123394', 'Persian_cat', 0.58622897)], [('n02123394', 'Persian_cat', 0.3944722)], [('n02123394', 'Persian_cat', 0.28453523)], [('n02102973', 'Irish_water_spaniel', 0.12897159)], [('n01622779', 'great_grey_owl', 0.3220467)], [('n02441942', 'weasel', 0.25759768)], [('n02441942', 'weasel', 0.4639576)], [('n02497673', 'Madagascar_cat', 0.21311994)], [('n02123394', 'Persian_cat', 0.31379968)], [('n02127052', 'lynx', 0.41493312)], [('n02113624', 'toy_poodle', 0.7856534)], [('n04399382', 'teddy', 0.16075166)], [('n02127052', 'lynx', 0.24749047)], [('n02127052', 'lynx', 0.27399546)], [('n01877812', 'wallaby', 0.16427185)], [('n02093647', 'Bedlington_terrier', 0.05776652)]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4sNQ6kdG6xym","colab_type":"text"},"source":["Создайте объект XGBClassifier со стандартными параметрами\n","\n","https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n","\n","Обучите его"]},{"cell_type":"markdown","metadata":{"id":"vnMOiOpii2ns","colab_type":"text"},"source":["Неправильная размерность в fit. Скорее всего надо преобразовать картинки"]},{"cell_type":"code","metadata":{"id":"kjFd57zs6xyo","colab_type":"code","outputId":"e6f52993-81cc-4bfc-c925-794a53c12a58","executionInfo":{"status":"error","timestamp":1585035544994,"user_tz":-240,"elapsed":742,"user":{"displayName":"George Zorikov","photoUrl":"","userId":"03587534006447719624"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["# Получите предсказания на тестовом и на обучающем множестве\n","clf = XGBClassifier()\n","\n","clf.fit(features_train, labels_train)\n","predicted_test = clf.predict(features_test)\n","\n","print(accuracy_score(labels_test, predicted_test))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-a2b6a4493a2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredicted_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             train_dmatrix = DMatrix(X, label=training_labels,\n\u001b[0;32m--> 726\u001b[0;31m                                     missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m         self._Booster = train(xgb_options, train_dmatrix, self.get_num_boosting_rounds(),\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[0;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \"\"\"\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input numpy.ndarray must be 2 dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;31m# flatten the array by rows and ensure it is float32.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# we try to avoid data copies if possible (reshape returns a view when possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input numpy.ndarray must be 2 dimensional"]}]},{"cell_type":"code","metadata":{"id":"r43PX4AS6xyt","colab_type":"code","colab":{}},"source":["# С помощью функции accuracy_score оцените результаты\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LcZjgLbu6xy2","colab_type":"text"},"source":["Почитайте про параметры XGBoost здесь: https://sites.google.com/view/lauraepp/parameters\n","Сделайте тюнинг гиперпараметров для XGBoost:\n","1. Подберите максимальный num_iterations при котором скор на валидации близок к максимальному, а скорость обучения ещё приемлимая\n","2. Для заданного num_iterations подберите подходящий learning rate\n","3. С помощью библиотеки hyperopt подберите остальные гиперпараметры при фиксимрованных num_iterations и learning_rate. Не подбирайте параметр early_stopping"]},{"cell_type":"code","metadata":{"id":"Sg0E_kQR6xy4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nZE8OKXN6xy9","colab_type":"text"},"source":["Оцените важность признаков с помощью поля feature_importances_\n","\n","Пользуясь списком https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a посмотрите, какие классы оказались наиболее важными (со значениями importance больше 0)\n","    \n","Изменяйте параметры, чтобы оставить только действительно важные признаки"]},{"cell_type":"code","metadata":{"id":"5PVLz6st6xy_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}